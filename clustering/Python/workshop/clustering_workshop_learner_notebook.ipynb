{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Workshop – Student Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this notebook to take notes and complete the challenges in your clustering workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop, we'll be looking at demographic data to identify different clusters of regions within major world cities. \n",
    "\n",
    "The goal is to identify naturally occurring groups within this demographic data. As a result, we should be able to better understand which parts of a city are similar and which are not.\n",
    "\n",
    "The figure below shows the result a result of similar analysis on demographic data for London. Parts of the city that are most similar to each other share the same colour.\n",
    "\n",
    "<img src=\"https://assets.decoded.com/managed/c6b02ff5-3899-40e5-8888-ad845beee77e_fxxqkyv_sev6lfd4.jpg\" alt=\"London map\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this code block to import libraries as you complete this notebook.\n",
    "# Be sure to leave a comment above each that explains what the library does and why it is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this workshop, we'll be using the dataset available at decd.co/da-resources in the clustering section. \n",
    "\n",
    "In this spreadsheet, you will find demographic data for four major world cities: London, Hong Kong, Amsterdam and New York. \n",
    "\n",
    "Each city is broken into several administrative districts. (London, for example, is made up of 33 boroughs, while Hong Kong is divided into 18 districts.) \n",
    "\n",
    "For each area in a city, you will find several different demographic features. These include things like population density, average salary, and average income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sourcing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing, take a moment to choose which of the four cities out you'd like to study for the rest of this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 1: Load the data for your chosen city into this notebook using pandas\n",
    "# Challenge 2: Check your data has imported correclty using .head()\n",
    "# Challenge 3: Add a text block above this code block explaining this section's purpose and what this code does"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring and transforming the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to spend time understanding your data before doing your analysis. Take a few moments to look through the data you've imported using some of the functions built into `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 4: Explore your data using the following functions: .head(), .tail(), .info(), and .dtypes\n",
    "# Challenge 5: Find another function you can use to explore your data online\n",
    "# Challenge 6: Add a text block beneath this code block describing what you've found in this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 7: Import the seaborn library into this notebook\n",
    "# Challenge 8: Create a scatter plot of two variables in your dataset using seaborn (support resource below)\n",
    "# Challenge 9: Add a text block beneath this code block describing what your visualisation shows\n",
    "# Challenge 10: (Optional) Try creating another visualisation using seaborn and describe what it shows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(See [Seaborn's official scatterplot documentation](https://seaborn.pydata.org/generated/seaborn.scatterplot.html) for support on Challenge 7.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running any clustering analysis, it is important to [_scale_ your data](https://medium.com/greyatom/why-how-and-when-to-scale-your-features-4b30ab09db5e).\n",
    "\n",
    "Scaling is trivial to do using the [Scale method](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html) from [scikit-learn](https://scikit-learn.org/stable/index.html).\n",
    "\n",
    "> scikit-learn (or sklearn) is the library most commonly used for machine learning in Python. It also has great documentation. Check out its [resources for clustering](https://scikit-learn.org/stable/modules/clustering.html#k-means).\n",
    "\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 11: Import the scale method from sklearn.preprocessing in your libraries section\n",
    "# Challenge 12: Uncomment and alter the code below to scale two features from your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_scaled = scale(df[['feature_1','feature_2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling with k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the k-means algorithm, you can use the KMeans method from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 13: Familiarise yourself with the KMeans scikit-learn documentation at: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "# Challenge 14: Create the KMeans model object using the commented code below (choose a reasonable value for \n",
    "# n_clusters based on your visualisation above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = KMeans(n_clusters = X, random_state= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 15: Fit the model using the code below\n",
    "model.fit(data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 16: Explore the labels in your model using the code below\n",
    "model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 17: Add the labels to your original dataframe using a version of the code below\n",
    "# df[\"cluster\"] = model.labels_.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 18: View your original dataframe and notice how it has changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 19: Copy your scatterplot from above and add hue = df['cluster'] to your list of arugments to visualise\n",
    "# your clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the results\n",
    "\n",
    "There are two ways we can evaluate the results of our analysis:\n",
    "1. Statistical methods\n",
    "2. Domain knowledge\n",
    "\n",
    "Statistical methods can give us a numeric understanding about the quality of our clusters. Our domain knowledge can help to interpret whether there are other factors that may not necessarily be explained by the numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within-cluster sum of squares\n",
    "A common statistical method to interpret our results is the within sum of squares method. This is simply the sum of the squared deviations from each observation and the cluster centroid.\n",
    "\n",
    "The idea is that, in general, a cluster that has a small sum of squares is more compact than a cluster that has a large sum of squares. Clusters that have higher values exhibit greater variability of the observations within the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 20: Use the .inertia_ attribute on your model to find the WSS value for your analysis\n",
    "# Challenge 21: Try using different values for k (n_clusters) in your algorithm above to see if you can reduce \n",
    "# this number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elbow method\n",
    "You can use the within-cluster sum of squares to establish what the ideal number of clusters is.\n",
    "\n",
    "It's helpful to start your analysis by plotting this value for different values of _k_ on a graph. Often, you will see a kink (or elbow) in the chart. This is often the optimum value for k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 22: Run the code below to identify the optimum number of clusters for this dataset and your chosen features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: peform k-means clustering for various k, and compute the WSS each time\n",
    "\n",
    "# create a list of the different values of k to test. Could also use: list(range(1,10))\n",
    "num_clusters = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# create a kmeans model for each value of k. Could use a regular for loop, but let's use a \"list comprehension\"!\n",
    "kmeans_list = [KMeans(n_clusters = i) for i in num_clusters]\n",
    "\n",
    "# For each value of k, fit the model with our data and use the \"inertia\" method of KMeans to compute the WSS\n",
    "scores = [kmeans_list[i-1].fit(data_scaled).inertia_ for i in num_clusters]\n",
    "\n",
    "# Optional \n",
    "# We can choose to normalise the scores with respect to the score for k=1 (the highest score)\n",
    "scores_normalised = scores/scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can choose to set a grid\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# Use the lineplot function from seaborn\n",
    "sns.lineplot(num_clusters, scores_normalised)\n",
    "\n",
    "# Add a title and axis labels\n",
    "plt.xlabel(\"Number of clusters k\")\n",
    "plt.ylabel(\"Score (normalised)\")\n",
    "plt.title(\"Elbow test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have your results, it's important to summarise them in a way that people will easily understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 23: Spend some time writing up a summary of your process and results. Write it as you would if you were\n",
    "# going to send it to a senior leadership team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way that is helpful to share your results is with a compelling visualisation. The code below shows how you could create a visualisation for London. It is optional to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Run the following code to plot your clusters on a map.\n",
    "# You will need to download the relevant shapefiles from decd.co/da-resources \n",
    "# and run adjust the code as needed. The example below is for London.\n",
    "\n",
    "# Import the relevant libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "%matplotlib inline\n",
    "\n",
    "# set the filepath and load in a shapefile\n",
    "fp = 'statistical-gis-boundaries-london/ESRI/London_Borough_Excluding_MHW.shp'\n",
    "map_df = gpd.read_file(fp)\n",
    "\n",
    "# check data type so we can see that this is not a normal dataframe, but a GEOdataframe\n",
    "map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that your plot works\n",
    "map_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge your existing dataset with the one you've just created\n",
    "merged = map_df.set_index('NAME').join(london_df.set_index('Borough'))\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a variable that will call whatever column we want to visualise on the map\n",
    "variable = 'cluster'\n",
    "# Set the range for the choropleth\n",
    "vmin, vmax = 120, 220\n",
    "# Create a figure and axes for Matplotlib\n",
    "fig, ax = plt.subplots(1, figsize=(10, 6))\n",
    "# Plot the figure\n",
    "merged.plot(variable, cmap='Blues', linewidth=0.8, ax=ax, edgecolor='0.8')\n",
    "# Turn off the axes\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a title\n",
    "ax.set_title('Similar boroughs in London', fontdict={'fontsize': '25', 'fontweight' : '3'})\n",
    "# create an annotation for the data source\n",
    "ax.annotate('Source: London Datastore',xy=(0.1, .08),  xycoords='figure fraction', horizontalalignment='left', verticalalignment='top', fontsize=12, color='#555555')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the figure as a .png file\n",
    "fig.savefig('london_clusters.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
